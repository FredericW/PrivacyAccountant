{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is a testing playground\n",
    "# Last Update: Always by Fei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fwei16/privacy\n"
     ]
    }
   ],
   "source": [
    "cd /home/fwei16/tensorflow_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "# Testing the @tf.function decorator and \n",
    "# tf.numpy_function\n",
    "# Save gradients to .npy files\n",
    "#=================================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "dpsgd_type=0\n",
    "var=0.25\n",
    "\n",
    "filename = ('test_%d_v%1.2f.npy' %(dpsgd_type, var))\n",
    "np.save(filename, np.empty(0))\n",
    "print(np.size(np.load(filename)))\n",
    "\n",
    "def my_numpy_func(grad):\n",
    "    noise_norm=np.linalg.norm(grad)/np.sqrt(np.size(grad))\n",
    "    filename = ('test_%d_v%1.2f.npy' %(dpsgd_type, var))\n",
    "    buf=np.load(filename)\n",
    "    buf=np.append(buf, noise_norm)\n",
    "    np.save(filename, buf)\n",
    "    return noise_norm.astype(np.float32)\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
    "def save_grad_norm(input):\n",
    "    return tf.numpy_function(my_numpy_func, [input], tf.float32)\n",
    "\n",
    "for _ in range(3):\n",
    "    test_grad=tf.ones((3,4))\n",
    "    save_grad_norm(test_grad)\n",
    "    \n",
    "print(np.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "# TESTING FOR TENSORFLOW @tf.function, tf.numpy_function DECORATORS\n",
    "#=================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def my_numpy_func(grad):\n",
    "    # x will be a numpy array with the contents of the input to the tf.function\n",
    "#     size=np.shape(grad)\n",
    "    stddev=0.5\n",
    "    scale=stddev/np.sqrt(2)\n",
    "    laplace=np.random.laplace(size=np.shape(grad), scale=0.4)\n",
    "    return  np.ndarray.astype(laplace, np.float32)\n",
    "        \n",
    "@tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
    "def add_noise(input):\n",
    "    y = tf.numpy_function(my_numpy_func, [input], tf.float32)\n",
    "    return y \n",
    "\n",
    "grad=tf.zeros((2,3))\n",
    "noise = add_noise(grad)\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "# TESTING FOR READING .tfrecords FILES\n",
    "#=================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "tf.executing_eagerly()\n",
    "\n",
    "filenames = ('privacy_data/sample_v%1.2f.tfrecords' %(var))\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "feature_description = {\n",
    "    'laplace': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32, default_value=0.0, allow_missing = True),\n",
    "    'cactus': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32, default_value=0.0, allow_missing = True),\n",
    "}\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return parsed\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "iterator=iter(parsed_dataset)\n",
    "iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "# TESTING FOR WRITTING .tfrecords FILES\n",
    "#=================================================\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from test_code.cactus_sampling import cactus_sample\n",
    "\n",
    "var = 0.25\n",
    "stddev = np.sqrt(var)\n",
    "d = stddev/np.sqrt(2)\n",
    "size = 30\n",
    "\n",
    "filename=('privacy_data/sample_v%1.2f.tfrecords' %(var))\n",
    "with tf.io.TFRecordWriter(filename) as writer:  \n",
    "  for i in range(size):\n",
    "    feature = {\n",
    "          'laplace': tf.train.Feature(float_list=tf.train.FloatList(\n",
    "              value=np.random.laplace(loc=0.0, size=1, scale=d))),\n",
    "          'cactus': tf.train.Feature(float_list=tf.train.FloatList(\n",
    "              value=cactus_sample(size=1, stddev=stddev))),\n",
    "      }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 28, 28, 1)\n",
      "(250, 14, 14, 16)\n",
      "(250, 13, 13, 16)\n",
      "(250, 5, 5, 32)\n",
      "(250, 5, 5, 32)\n",
      "(250, 800)\n",
      "(250, 32)\n",
      "(250, 10)\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "#   testing the TF model\n",
    "#=================================================\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "input_shape=(250, 28, 28, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(16, 8,\n",
    "                       strides=2,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       input_shape=(28, 28, 1))(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.MaxPool2D(2, 1)(x)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Conv2D(32, 4,\n",
    "                       strides=2,\n",
    "                       padding='valid',\n",
    "                       activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.MaxPool2D(2, 1,padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x=tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "\n",
    "stddev = 1\n",
    "sen = 1\n",
    "\n",
    "normal_dist0 = stats.norm(loc=0, scale=stddev)\n",
    "normal_dist1 = stats.norm(loc=sen, scale=stddev)\n",
    "\n",
    "delta = 1e-4\n",
    "big_grid = np.arange(-8,8,delta)\n",
    "\n",
    "pmfc = kernel.pdf(big_grid)*delta\n",
    "\n",
    "pmf0 = normal_dist0.pdf(big_grid)*delta\n",
    "\n",
    "pmf1 = normal_dist1.pdf(big_grid)*delta\n",
    "\n",
    "conv_pmf0 = signal.convolve(pmfc,pmf0,'same')\n",
    "conv_pmf1 = signal.convolve(pmfc,pmf1,'same')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.2792962   1.14857945  1.27760423 -4.22266871]\n",
      "  [ 0.9232829  -1.27214551  2.44126153 -4.48867703]\n",
      "  [-4.88676992  0.18202779  0.17846516  0.82104495]]\n",
      "\n",
      " [[-0.72686736  0.35453578  2.08125742 -1.79049484]\n",
      "  [-1.0723485  -0.98825891 -1.18278631  2.25246997]\n",
      "  [ 2.25834941 -2.69134059  1.04788004  0.89179998]]]\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "#   testing the new cactus sampling function\n",
    "#=================================================\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "grad=np.zeros(shape=(2,3,4))\n",
    "\n",
    "size=np.shape(grad)\n",
    "\n",
    "def cactus_sample(stddev,size,sen):\n",
    "  filename = ('privacy_data/cactus_samples_d%d_v%1.2f.npy' %(sen, stddev**2))\n",
    "  samples=np.load(filename)\n",
    "\n",
    "  result=np.zeros(size).reshape(-1)\n",
    "  for a in range(len(result)):\n",
    "\n",
    "    rand=np.random.uniform(0,len(samples),1)\n",
    "    result[a]=samples[int(rand)]\n",
    "\n",
    "  result=result.reshape(size)\n",
    "\n",
    "  return result\n",
    "\n",
    "result=cactus_sample(stddev=1,size=size,sen=1)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy",
   "language": "python",
   "name": "privacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
